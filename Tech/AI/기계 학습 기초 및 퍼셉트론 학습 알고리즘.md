# 기계 학습 기초 및 퍼셉트론 학습 알고리즘



이 게시물에서는 기계 학습 및 퍼셉트론 학습 알고리즘의 기본 아이디어를 얻을 수 있습니다.

기계 학습은 소프트웨어 업계에서 사람들이 자주 이야기하는 용어이며 날이 갈수록 더욱 대중화되고 있습니다. 미디어는 딥 러닝, OpenCV, TensorFlow 등 멋진 기계 학습 관련 단어로 가득 차 있습니다. [소프트웨어 업계에 종사하지 않는 사람들도 기계 학습의 힘을 활용하려고 합니다](http://s3.amazonaws.com/files.technologyreview.com/whitepapers/MITTR_GoogleforWork_Survey.pdf) . 모든 비즈니스에서 그 적용이 나날이 더 널리 퍼지고 있다는 것은 놀라운 일이 아닙니다.

그러나 우리의 마음이 너무나 많은 놀라운 기계 학습 아이디어와 용어로 가득 차 있을 때 기계 학습의 기본을 무시하거나 단순히 잊어버리기 쉽습니다. 이 기사는 기계 학습의 기본 사항을 검토하는 것뿐만 아니라 기계 학습을 처음 배우는 사람들에게 기계 학습이 무엇인지, 어떻게 작동하는지, 잘 수행하는 방법을 알 수 있도록 기계 학습에 대한 간략한 개념을 제공하는 것을 목표로 합니다. , 기계 학습이 마술이 아니라는 것을 깨닫습니다.

숙련된 독자는 기계 학습의 기본 개념을 검토하고 초보자는 이 기사에서 기계 학습의 기본 아이디어를 얻을 수 있기를 바랍니다.

## 기계 학습이란 무엇입니까? 그게 뭘 할 수 있지?

기계 학습은 인공 지능의 하위 분야입니다. 그 이름이 적용되는 것처럼 기계가 데이터에서 무언가를 ''학습''하도록 돕습니다. 예를 들어, 우리가 어렸을 때 개와 같은 동물을 인식하는 법을 어떻게 배웠는지 기억하십니까? 우리는 아마도 개 그림, 즉 데이터가 포함된 책을 읽기 시작했을 것이고, 이후 개를 만났을 때 그것이 개라는 것을 알게 될 것입니다. 이것이 기계 학습의 본질입니다. 즉, 데이터에서 학습하는 것입니다.

예를 들어 개념을 설명하는 것은 항상 쉽습니다. 제가 몇 년 전에 참가한 이 Kaggle 대회인 [Predict Grant Applications는 검토 프로세스를 단순화하고 가속화하여 비용을 줄이는 데 도움이 되는 모델을 제공할 수 있는 참가자에게 상을 수여했습니다.](https://www.kaggle.com/c/unimelb#description)

신청자가 보조금을 받을 자격이 있는지를 결정하는 전통적인 방법은 학술 검토자가 신청자의 문서를 검토하고 결정을 내리는 데 시간을 보내는 것입니다. 이 과정은 꽤 많은 시간이 걸립니다. 특히 이 학교는 대부분의 지원서가 거절당한다고 주장합니다. 귀중한 학술 리뷰어의 시간이 낭비됩니다.

여기에서 기계 학습이 도움이 될 수 있습니다. 기계 학습 접근 방식은 기계 학습 접근 방식이 성공할 가능성이 높다고 예측하는 응용 프로그램을 사전에 필터링할 수 있습니다. 따라서 검토 위원회는 이러한 후보에 시간을 할애할 수 있습니다.

따라서 기계 학습의 주요 목표는 컨텍스트 관련 데이터로 수학적 모델을 훈련하여 미래를 추론하거나 결정을 내리는 것입니다.

### 어떻게 작동합니까?

기계 학습은 데이터에서 시작됩니다. 이 질문에 답하기 전에 먼저 데이터를 살펴보겠습니다. 다음 표는 Predict Grant Applications 데이터 세트의 발췌 부분을 보여줍니다. 이 표는 샘플, 기능 및 레이블과 같은 기계 학습 영역에서 사용되는 일반적인 표기법을 보여줍니다.

![이미지 1](https://www.codeproject.com/KB/Articles/1211753/pga_data_set-r-700.png)

그렇다면 머신러닝은 어떻게 작동할까요? 우선, Predict Grant Applications 예제에서 일부 속성이 다른 속성보다 더 무거운 가중치를 갖는다는 데 모두가 동의할 것입니다. 심사 위원회뿐만 아니라 심사 과정에서 학술 심사자는 일부 속성이 다른 속성보다 더 중요하다는 느낌을 가질 수 있습니다. 예를 들어 저널 기사의 수는 애플리케이션의 개인 ID보다 더 중요할 수 있습니다. 이 사실은 성공적인 응용 프로그램의 패턴이 존재함을 의미합니다. 둘째, 패턴이 존재한다는 것을 안다 하더라도 누구에게 부여할지 결정하기 위해 수학 공식을 쓰는 것은 불가능합니다(또는 매우 어렵습니다). 그렇지 않으면 수학 공식을 사용하여 이 문제를 한 번에 해결하는 프로그램을 작성할 것입니다. 셋째, 이 학교는 이 프로그램에 대한 역사적 기록을 가지고 있습니다. 즉, 데이터가 있습니다.

1. 패턴이 존재합니다. (이 Predict Grant Applications 예에서 검토자는 일부 속성이 다른 속성보다 더 중요하다고 생각합니다.)
2. 수학 방정식으로 이 문제를 풀 수 있는 쉬운 방법은 없습니다. (아마 이것이 기계 학습 접근 방식이 필요한 주된 이유일 것입니다. 수학 공식 솔루션은 찾을 수 있다면 항상 기계 학습 솔루션보다 낫습니다.)
3. 데이터가 있습니다. (이 예에서 University of Melbourne은 과거 애플리케이션 기록을 보유하고 있습니다. 데이터가 없으면 머신 러닝이 할 수 있는 일이 없습니다.)

문제가 이 세 가지 사항을 충족하면 기계 학습이 이 문제를 해결할 준비가 됩니다. 기본 기계 학습 접근 방식에는 다음과 같은 구성 요소가 있습니다.

- 목표 함수: 알 수 없는 이상 함수. 존재하지만 알려지지 않음
- 가능한 모든 기능을 포함하는 가설 집합. 예를 들어 퍼셉트론, 신경망, 지원 벡터 머신 등이 있습니다.
- 데이터를 기반으로 설정된 가설에서 최적의 함수를 선택하는 학습 알고리즘입니다. 예를 들어 Perceptron Learning Algorithm, backpropagation, quadratic programming 등이 있습니다.
- 학습 모델: 일반적으로 가설 세트와 학습 알고리즘의 조합을 학습이라고 할 수 있습니다.

![이미지 2](https://www.codeproject.com/KB/Articles/1211753/ml_basic_cr.png)

기계 학습 문제를 해결하기 위한 많은 도구, 즉 학습 모델이 있습니다. 따라서 첫 번째 단계는 시작할 학습 모델을 선택하는 것입니다. 각 학습 모델에는 강점과 약점이 있습니다. 일부는 특정 문제에 능숙할 수 있습니다. 일부는 아닐 수도 있습니다. 적절한 학습 모델을 선택하는 방법은 이 기사의 주제에서 벗어나지만 적어도 하나는 항상 시작점으로 선택할 수 있습니다.

학습 모델을 선택하자마자 데이터를 공급하여 모델 교육을 시작할 수 있습니다. Predict Grant 신청서를 다시 예로 들어 보겠습니다. 이 프로세스는 무작위 요소, 즉 각 속성의 가중치로 시작합니다. 그런 다음 이러한 요소를 변경하여 검토자가 일반적으로 지원자가 승인되었는지 여부를 결정하는 방법을 궁극적으로 예측할 수 있을 때까지 과거 기록을 제공하여 학술 검토자가 이전에 애플리케이션을 검토한 방식과 점점 더 일치하도록 만듭니다. 이 프로세스를 학습 모델이라고 합니다.

모델이 학습된 후 모델은 새 데이터를 공급하여 결과를 예측할 수 있습니다. Predict Grant Application 예에서 새 데이터는 현재 연도의 애플리케이션일 수 있습니다. 대학은 이 모델을 사용하여 성공 가능성이 낮은 애플리케이션을 필터링할 수 있으므로 검토 위원회는 성공 가능성이 높은 애플리케이션에 집중할 수 있습니다.

기계 학습 접근 방식의 이점은 더 많은 차원에서 훨씬 더 큰 데이터 세트로 일반화할 수 있다는 것입니다. 문제가 차원 수가 적은 경우(예: 특성 수)에는 문제가 없습니다. 그러나 현실은 University of Melbourne이 제공한 데이터 세트에 249개의 기능이 있어 이 문제를 훨씬 더 어렵게 만듭니다(간단한 수학 공식으로 고정하는 것이 거의 불가능함). 다행히 기계 학습의 힘은 더 많은 기능을 가진 데이터의 경우 직접 적용하고 평가할 수 있다는 것입니다.

다음 섹션에서는 아마도 가장 간단한 학습 모델을 사용하여 기계 학습 접근 방식의 기본 워크플로우를 보여줍니다.

## 간단한 예: 퍼셉트론 학습 알고리즘

[이 예제에서는 각각 50개의 인스턴스로 구성된 3개의 클래스를 포함하는 Iris Data Set](https://archive.ics.uci.edu/ml/datasets/Iris) 이라는 클래식 데이터 세트를 사용합니다 . 여기서 각 클래스는 붓꽃 식물의 유형을 나타냅니다. 이 예제의 목표는 기계 학습 방식을 사용하여 붓꽃 종류를 분류하는 프로그램을 구축하는 것입니다.

### 문제 설정

Iris 데이터 세트에는 Iris Setosa, Iris Versicolour 및 Iris Virginica의 세 가지 클래스(일반적으로 클래스는 레이블로도 참조될 수 있음)가 포함되어 있습니다.

클래스 외에 각 인스턴스에는 다음 속성이 있습니다.

- 꽃받침 길이(cm)
- 꽃받침 폭(cm)
- 꽃잎 길이(cm)
- 꽃잎 너비(cm)

Iris 데이터 세트의 각 인스턴스(일명 샘플)는 다음과 같습니다(5.1, 3.5, 1.4, 0.2, Iris-setosa).

![이미지 3](https://www.codeproject.com/KB/Articles/1211753/iris_data-r-700.png)

이 예제에서 선택한 학습 모델은 Perceptron 및 Perceptron Learning Algorithm입니다.

### 퍼셉트론 학습 알고리즘

퍼셉트론 학습 알고리즘은 인공 신경망의 가장 단순한 형태, 즉 단층 퍼셉트론입니다. 퍼셉트론은 인공 신경망의 기본 단위인 생물학적 뉴런의 모델로 고안된 인공 뉴런입니다. 인공 뉴런은 특정(하나 이상) 입력과 해당 가중치 벡터의 선형 조합입니다. 즉, 퍼셉트론에는 다음과 같은 정의가 있습니다.

교육 데이터 세트 및 출력 레이블이 ![디](https://www.codeproject.com/KB/Articles/1211753/9d728f76-7c53-4c9a-8282-260cde096a1e.Png)포함된 데이터 세트가 주어지고 행렬로 형성될 수 있습니다.![엑스](https://www.codeproject.com/KB/Articles/1211753/fe5a7135-8713-4f9a-975c-faaf37ff1d4f.Png)![와이](https://www.codeproject.com/KB/Articles/1211753/79815107-85d2-4ca8-affe-8901d1ddead4.Png)

![이미지 7](https://www.codeproject.com/KB/Articles/1211753/perceptron_math-r-700.png)
각각은 ![x_i](https://www.codeproject.com/KB/Articles/1211753/7269e66b-a3d7-4f1d-aff6-a47a228be03b.Png)의 하나의 샘플 ![엑스](https://www.codeproject.com/KB/Articles/1211753/19a9d335-739c-4ad4-a2ed-d9736b005639.Png)이고 ![x_i = \left\{ x_{i1}, x_{i2}, ..., x_{in} \right\} \forall i \in N, i = 1, 2,..., n](https://www.codeproject.com/KB/Articles/1211753/ce1f6f81-3dc8-4aa2-a593-e52615781db9.Png)
각각 ![y_i](https://www.codeproject.com/KB/Articles/1211753/ef07591b-6f49-4431-ba84-45502c9570b1.Png)은 실제 레이블이며 이진 값을 가집니다: ![\왼쪽\{ -1, 1 \오른쪽\}](https://www.codeproject.com/KB/Articles/1211753/7be0a919-2f6a-4650-ac0c-96f9ada06c23.Png).
![여](https://www.codeproject.com/KB/Articles/1211753/f4fb971d-6d45-4064-8c7f-333ef6f1183d.Png)가중치 벡터입니다. 퍼셉트론은 와 의 선형 ![x_{ij}](https://www.codeproject.com/KB/Articles/1211753/0755dcd9-f2ef-466b-8ed2-5e418cb3fd87.Png)조합 ![w_j](https://www.codeproject.com/KB/Articles/1211753/5afbd7fc-e551-4016-9b60-55a10b23c413.Png)
이므로 다음과 같이 나타낼 수 있습니다. 각 뉴런에 대해 출력은 이며 여기서 는 전달 함수입니다. 단순화를 위해 다음과 같이 취급할 수 있습니다 . 및 의 선형 조합은 다음과 같이 다시 쓸 수 있습니다. j 번째 뉴런 의 출력은 입니다 . 여기서 는 전달 함수입니다.![엑스](https://www.codeproject.com/KB/Articles/1211753/35024194-2aac-47a2-9fcc-564d530d50bb.Png)![여](https://www.codeproject.com/KB/Articles/1211753/0e6d75df-2f18-4f7f-81de-0d9b09a0ab39.Png)![\begin{bmatrix} x_{11} & \cdots & x_{1n} \\ \vdots & x_{ij} & \vdots \\ x_{m1} & \cdots & x_{mn} \end{bmatrix} \begin {bmatrix} w_1 \\ \vdots \\ w_n \end{bmatrix}](https://www.codeproject.com/KB/Articles/1211753/cb950365-e747-4510-aa2f-4707274ca70a.Png)
![y_j](https://www.codeproject.com/KB/Articles/1211753/714fd475-8f03-4e29-9c76-6c96731d9f64.Png)![y_j = \phi \left( \displaystyle\sum_{j=1}^{n}x_{ij}w_j \right)](https://www.codeproject.com/KB/Articles/1211753/23c731b7-0014-428e-b255-a53d97ccc2d3.Png)![\파이](https://www.codeproject.com/KB/Articles/1211753/fb237007-f36d-406b-bc77-2183b509505d.Png)
![\phi = \begin{cases} 1 & \quad \text{if } \sum_{j=1}^{n}x_{ij}w_j>\theta \text{ 여기서 } \theta \text{는 미리 정의된 임계값입니다. } \\ -1 & \quad \text{그렇지 않으면} \end{경우}](https://www.codeproject.com/KB/Articles/1211753/49a69c8b-ab1c-4867-b090-ac50a0a9ee22.Png)
![\파이](https://www.codeproject.com/KB/Articles/1211753/a71d141b-77bd-4a6f-98cc-b8f8652bdef0.Png)![x_{i0}w_0](https://www.codeproject.com/KB/Articles/1211753/f088df9c-2d9e-46ad-841d-77da92e2a29c.Png)![x_{i0} = 1](https://www.codeproject.com/KB/Articles/1211753/823b4c4d-3f53-4c66-b13b-a7ba0b0981ed.Png)
![엑스](https://www.codeproject.com/KB/Articles/1211753/94555f20-f5a9-4139-88d2-73a3657e98b7.Png)![여](https://www.codeproject.com/KB/Articles/1211753/2cc69998-3b7f-47ff-83aa-bf21d5d38018.Png)![\begin{bmatrix} x_{01} & \cdots & x_{0n} \\ \vdots & x_{ij} & \vdots \\ x_{m1} & \cdots & x_{mn} \end{bmatrix} \begin {bmatrix} w_0 \\ \vdots \\ w_n \end{bmatrix}](https://www.codeproject.com/KB/Articles/1211753/10b13f90-6ad8-421e-b44b-37d6f1ffe1d3.Png)
![y_j = \phi \left( \displaystyle\sum_{j=0}^{n}x_{ij}w_j \right)](https://www.codeproject.com/KB/Articles/1211753/d3956bb7-cbde-4572-aea8-c74896ae3ce1.Png)![\파이](https://www.codeproject.com/KB/Articles/1211753/997b736f-f07b-4f66-aca9-ad7f791c5e03.Png)
![\phi = \begin{cases} 1 & \quad \text{if } \sum_{j=0}^{n}x_{ij}w_j>\theta \text{ 여기서 } \theta \text{는 미리 정의된 임계값입니다. } \\ -1 & \quad \text{그렇지 않으면} \end{경우}](https://www.codeproject.com/KB/Articles/1211753/e323fb8f-734a-4f95-92c6-ff03807bc8b8.Png)

### 학습 단계

![이미지 32](https://www.codeproject.com/KB/Articles/1211753/learning_steps-r-700.png)

Perception의 정의에 따라 Perceptron 학습 알고리즘은 다음 단계에 따라 작동합니다.

1. 가중치를 0 또는 작은 난수로 초기화합니다.

2. 각 학습 샘플에 대해 

   

   다음 하위 단계를 수행합니다.

   1. 및 ![\파이](https://www.codeproject.com/KB/Articles/1211753/3ad1b46b-d1ac-4fce-9ba5-09a56a7ba032.Png)의 선형 조합을 계산하여 예측 출력 클래스 레이블을 얻습니다 .![엑스](https://www.codeproject.com/KB/Articles/1211753/ed648ffe-1d90-468b-8d93-2854f3db9c6b.Png)![여](https://www.codeproject.com/KB/Articles/1211753/2d888485-1f26-4524-8042-3020127c31ad.Png)![p_j](https://www.codeproject.com/KB/Articles/1211753/b466a3f6-aaa7-4fd1-9566-f77779d2a8ff.Png)
   2. 가중치 업데이트![여](https://www.codeproject.com/KB/Articles/1211753/18164b4f-a3dd-4be6-991e-578195d85187.Png)
   3. 오분류 횟수 기록

3. 전체 집합을 훈련시킨 후 오분류의 수가 0이 아니면 ![엑스](https://www.codeproject.com/KB/Articles/1211753/d2d4dee6-3c4c-48ff-bba3-c066f31d81a2.Png)2단계를 반복하여 훈련 집합의 처음부터 시작한다. 즉, 에서 시작한다 ![x_{0j}](https://www.codeproject.com/KB/Articles/1211753/1d3478e6-4578-4088-ab23-1d257594a001.Png). 오분류 수가 0이 될 때까지 이 단계를 반복합니다.

**참고** :

2.1의 출력은 함수에 의해 예측된 클래스입니다 ![\파이](https://www.codeproject.com/KB/Articles/1211753/801a5eac-b166-4763-b315-9e337ecc7fc6.Png).

2.2단계에서 각 가중치의 업데이트는 다음 규칙을 따릅니다 ![w_j](https://www.codeproject.com/KB/Articles/1211753/6fdb4a9f-9a63-4d77-90c2-ec6948aa1b3f.Png).![여](https://www.codeproject.com/KB/Articles/1211753/c04ff0c1-b1a4-44c6-b7bc-9ef02e15a88a.Png)

![w_j \left( t + 1\right) = w_j \left( t \right) + \Delta w_j = w_j \left( t \right) + \left( p_j - y_j \right) x_{ij}](https://www.codeproject.com/KB/Articles/1211753/a8004c25-721a-4c5a-8c22-65c4b9807809.Png), 여기서 는 ![티](https://www.codeproject.com/KB/Articles/1211753/74e9f75a-cafc-4bd6-9960-c3d4bef539eb.Png)단계를 나타냅니다: ![티](https://www.codeproject.com/KB/Articles/1211753/28a255a2-5ab4-4ad5-9a59-76d4b5196488.Png)현재 단계를 의미하고 ![t+1](https://www.codeproject.com/KB/Articles/1211753/7aa540ea-c391-4b74-b93a-486a9d0e97dc.Png)다음 단계를 의미합니다. 따라서 ![w_j\왼쪽( t \오른쪽)](https://www.codeproject.com/KB/Articles/1211753/dd076b5a-533d-441b-96b9-c17a02bcf21e.Png)현재 무게를 표시하고 ![w_j\왼쪽( t+1 \오른쪽)](https://www.codeproject.com/KB/Articles/1211753/6f8decd1-c4de-43fb-822a-f572bcf3795c.Png)업데이트 후 무게를 표시합니다.

잘못 분류하지 않은 경우 ![\Delta w_j = \left( -1 - \left( -1 \right) \right) x_{ij} = 0](https://www.codeproject.com/KB/Articles/1211753/74cd58b4-d0aa-4b62-bd3e-765c42f11b9e.Png)또는 ![\Delta w_j = \left( 1 - 1 \right) x_{ij} = 0](https://www.codeproject.com/KB/Articles/1211753/a8207d32-7527-4bf0-a646-eb2ea0bdf612.Png). 이 경우 ![w_j \left( t + 1 \right) = w_j \left( t \right)](https://www.codeproject.com/KB/Articles/1211753/ccd97361-aae2-4c17-aa68-6bcf935d3f02.Png). 업데이트가 없습니다.

잘못 분류한 경우 ![\Delta w_j = \left( -1 - 1 \right) x_{ij} = -2 x_{ij}](https://www.codeproject.com/KB/Articles/1211753/161acc55-6121-484e-96b4-7a8a596005d1.Png)또는 ![\Delta w_j = \left( 1 - \left( -1 \right) \right) x_{ij} = 2 x_{ij}](https://www.codeproject.com/KB/Articles/1211753/671641cb-e41f-49a2-a506-1a8b0cc1a1f3.Png). 이 경우 ![w_j \left( t + 1 \right) = w_j \left( t \right) + 2 x_{ij}](https://www.codeproject.com/KB/Articles/1211753/ca678629-8dcb-4f03-8e46-f71003f5cd7b.Png)또는 ![w_j \left( t + 1 \right) = w_j \left( t \right) - 2 x_{ij}](https://www.codeproject.com/KB/Articles/1211753/9c7b0eda-0daa-473c-8482-cbc4cb6a53b2.Png). 체중 업데이트.

2.3단계에서 PLA의 수렴은 두 클래스가 선형적으로 분리 가능한 경우에만 보장됩니다. 그렇지 않은 경우 PLA는 절대 멈추지 않습니다. 한 가지 간단한 수정은 Pocket Learning Algorithm이며, 이는 향후 게시물에서 논의될 것입니다.

퍼셉트론 학습 알고리즘은 다음과 같이 간단하게 구현할 수 있습니다.

파이썬

축소 ▲  

```python
import numpy as np

class PerceptronClassifier:
    '''Preceptron Binary Classifier uses Perceptron Learning Algorithm
       to do classification with two classes.

       Parameters
       ----------
       number_of_attributes : int
           The number of attributes of data set.

       Attributes
       ----------
       weights : list of float
           The list of weights corresponding &amp;lt;
           g class="gr_ gr_313 gr-alert gr_gramm gr_inline_cards gr_run_anim 
           Grammar multiReplace" id="313" data-gr-id="313"&amp;gt;with&amp;
           lt;/g&amp;gt; input attributes.

       errors_trend : list of int
           The number of misclassification for each training sample.
       '''
    def __init__(self, number_of_attributes: int):
        # Initialize the weigths to zero
        # The size is the number of attributes plus the bias, i.e. x_0 * w_0
        self.weights = np.zeros(number_of_attributes + 1)

        # Record of the number of misclassify for each train sample
        self.misclassify_record = []

        self._label_map = {}
        self._reversed_label_map = {}

    def _linear_combination(self, sample):
        '''linear combination of sample and weights'''
        return np.inner(sample, self.weights[1:])

    def train(self, samples, labels, max_iterator=10):
        '''Train the model

        Parameters
        ----------
        samples : two dimensions list
            Training data set
        labels : list of labels
            Class labels. The labels can be anything as long as it has 
                          only two types of labels.
        max_iterator : int
            The max iterator to stop the training process
            in case the training data is not converaged.
        '''
        # Build the label map to map the original labels to numerical labels
        # For example, ['a', 'b', 'c'] -&amp;gt; {0 : 'a', 1 : 'b', 2 : 'c'}
        self._label_map = {1 : list(set(labels))[0], -1 : list(set(labels))[1]}
        self._reversed_label_map = {value : key for key, value in self._label_map.items()}

        # Transfer the labels to numerical labels
        transfered_labels = [self._reversed_label_map[index] for index in labels]

        for _ in range(max_iterator):
            misclassifies = 0
            for sample, target in zip(samples, transfered_labels):
                linear_combination = self._linear_combination(sample)
                update = target - np.where(linear_combination &amp;gt;= 0.0, 1, -1)

                # use numpy.multiply to multiply element-wise
                self.weights[1:] += np.multiply(update, sample)
                self.weights[0] += update

                # record the number of misclassification
                misclassifies += int(update != 0.0)

            if misclassifies == 0:
                break
            self.misclassify_record.append(misclassifies)

    def classify(self, new_data):
        '''Classify the sample based on the trained weights

        Parameters
        ----------
        new_data : two dimensions list
            New data to be classified

        Return
        ------
        List of int
            The list of predicted class labels.
        '''
        predicted_result = np.where((self._linear_combination(new_data) + 
                                     self.weights[0]) &amp;gt;= 0.0, 1, -1)
        return [self._label_map[item] for item in predicted_result]
```

### 홍채 데이터 세트에 퍼셉트론 학습 알고리즘 적용

일반적으로 기계 학습 알고리즘을 데이터 세트에 적용하는 첫 번째 단계는 데이터 세트를 기계 학습 알고리즘이 인식할 수 있는 무언가 또는 형식으로 변환하는 것입니다. 이 프로세스에는 정규화, 차원 축소 및 기능 엔지니어링이 포함될 수 있습니다. 예를 들어 대부분의 기계 학습 알고리즘은 숫자 데이터만 허용합니다. 따라서 데이터 세트를 숫자 형식으로 변환해야 합니다.

Iris Data Set에서 속성인 꽃받침 길이, 꽃받침 너비, 꽃잎 길이, 꽃잎 너비는 숫자 값이지만 클래스 레이블은 숫자 값이 아닙니다. 따라서 의 구현에서 `PerceptronClassifier`train 함수는 클래스 레이블을 숫자 형식으로 전송합니다. 간단한 방법은 숫자를 사용하여 이러한 레이블을 나타내는 것입니다. 즉, 0은 Setosa를, 1은 Versicolour를, 2는 Virginica를 의미합니다. 그런 다음 Iris Data Set은 Perceptron Learning Algorithm에 입력하기 위해 아래 형식으로 볼 수 있습니다.

![X = \left\{ x_0, x_1, x_2, x_3, x_4 \right\} = \left\{ 1, 꽃받침 길이, 꽃받침 너비, 꽃잎 길이, 꽃잎 너비 \right\}](https://www.codeproject.com/KB/Articles/1211753/837c6934-1477-43d8-925d-8a5c632e1fbb.Png)

![Y = \왼쪽\{ 0, 1, 2 \오른쪽\}](https://www.codeproject.com/KB/Articles/1211753/203caf25-faf3-4957-bf6d-237586553ce8.Png)

퍼셉트론은 이진 분류기입니다. 그러나 Iris 데이터 세트에는 세 개의 레이블이 있습니다. 다중 클래스 문제를 처리하는 일반적인 두 가지 방법은 일대다 및 일대일입니다. 이 섹션에서는 단순화된 일대일 전략을 사용하여 붓꽃 식물의 유형을 결정합니다.

일대일 접근 방식은 각 클래스 쌍에 대한 모델을 교육하고 다수결로 올바른 클래스를 결정합니다. 예를 들어 Iris 데이터 세트에는 세 가지 클래스가 있습니다. 그것은 세 클래스의 쌍의 모든 조합을 의미합니다. 즉 ![\left\{ \left\{ setosa, 버시컬러 \right\}, \left\{ setosa, virginica \right\}, \left\{ 버시컬러, virginica \right\} \right\}](https://www.codeproject.com/KB/Articles/1211753/799e0d78-bd58-4462-8c18-ea597b33e44d.Png), .

게다가 기계 학습은 데이터 세트가 가진 모든 기능을 사용하도록 제한되지 않습니다. 대신 중요한 기능만 필요합니다. 여기서는 꽃받침 너비와 꽃잎 너비라는 두 가지 기능만 고려합니다. 사실, 올바른 기능을 선택하는 것은 매우 중요해서 이 문제를 다루는 기능 엔지니어링이라는 주제가 있습니다.

파이썬

축소 ▲  

```python
import numpy as np
import pandas as pd
import urllib.request
from perceptronlib.perceptron_classifier import PerceptronClassifier

# Download Iris Data Set from http://archive.ics.uci.edu/ml/datasets/Iris
url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'
urllib.request.urlretrieve(url, 'iris.data')
# Use pandas.read_csv module to load iris data set
# http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html
IRIS_DATA = pd.read_csv('iris.data', header=None)

# Prepare the training data and test data
# The original Iris Data Set has 150 samples and 50 samples for each class
# This example takes first 40 samples of each class as training data,
# and the other 10 samples of each class as testing data.
# So, this example uses the testing data to verify the trained Perceptron learning model.
# 0 ~ 39: setosa training set
# 40 ~ 49: setosa testing set
# 50 ~ 89 versicolor training set
# 90 ~ 99: versicolor testing set
# 100 ~ 139: virginica training set
# 140 ~ 149: virginica testing set
# Use pandas iloc to select samples by position and return an one-dimension array
# http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.iloc.html#pandas.DataFrame.iloc
SETOSA_LABEL = IRIS_DATA.iloc[0:40, 4].values
VERSICOLOR_LABEL = IRIS_DATA.iloc[50:90, 4].values
VIRGINICA_LABEL = IRIS_DATA.iloc[100:140, 4].values

SETOSA_VERSICOLOR_TRAINING_LABEL = np.append(SETOSA_LABEL, VERSICOLOR_LABEL)
SETOSA_VIRGINICA_TRAINING_LABEL = np.append(SETOSA_LABEL, VIRGINICA_LABEL)
VERSICOLOR_VIRGINICA_TRAINING_LABEL = np.append(VERSICOLOR_LABEL, VIRGINICA_LABEL)

# In this example, it uses only Sepal width and Petal width to train.
SETOSA_DATA = IRIS_DATA.iloc[0:40, [1, 3]].values
VERSICOLOR_DATA = IRIS_DATA.iloc[50:90, [1, 3]].values
VIRGINICA_DATA = IRIS_DATA.iloc[100:140, [1, 3]].values

# Use one-vs-one strategy to train three classes data set, so we need three binary classifiers
# setosa-versicolor, setosa-viginica, and versicolor-viginica
SETOSA_VERSICOLOR_TRAINING_DATA = np.append(SETOSA_DATA, VERSICOLOR_DATA, axis=0)
SETOSA_VIRGINICA_TRAINING_DATA = np.append(SETOSA_DATA, VIRGINICA_DATA, axis=0)
VERSICOLOR_VIRGINICA_TRAINING_DATA = np.append(VERSICOLOR_DATA, VIRGINICA_DATA, axis=0)

# Prepare test data set. Use only Sepal width and Petal width as well.
SETOSA_TEST = IRIS_DATA.iloc[40:50, [1, 3]].values
VERSICOLOR_TEST = IRIS_DATA.iloc[90:100, [1, 3]].values
VIRGINICA_TEST = IRIS_DATA.iloc[140:150, [1, 3]].values
TEST = np.append(SETOSA_TEST, VERSICOLOR_TEST, axis=0)
TEST = np.append(TEST, VIRGINICA_TEST, axis=0)

# Prepare the target of test data to verify the prediction
SETOSA_VERIFY = IRIS_DATA.iloc[40:50, 4].values
VERSICOLOR_VERIFY = IRIS_DATA.iloc[90:100, 4].values
VIRGINICA_VERIFY = IRIS_DATA.iloc[140:150, 4].values
VERIFY = np.append(SETOSA_VERIFY, VERSICOLOR_VERIFY)
VERIFY = np.append(VERIFY, VIRGINICA_VERIFY)

# Define a setosa-versicolor Perceptron() with 2 attributes
perceptron_setosa_versicolor = PerceptronClassifier(2)
# Train the model
perceptron_setosa_versicolor.train(SETOSA_VERSICOLOR_TRAINING_DATA, 
                                   SETOSA_VERSICOLOR_TRAINING_LABEL)

# Define a setosa-virginica Perceptron() with 2 attributes
perceptron_setosa_virginica = PerceptronClassifier(2)
# Train the model
perceptron_setosa_virginica.train(SETOSA_VIRGINICA_TRAINING_DATA, 
                                  SETOSA_VIRGINICA_TRAINING_LABEL)

# Define a versicolor-virginica Perceptron() with 2 attributes
perceptron_versicolor_virginica = PerceptronClassifier(2)
# Train the model
perceptron_versicolor_virginica.train(VERSICOLOR_VIRGINICA_TRAINING_DATA, 
                                      VERSICOLOR_VIRGINICA_TRAINING_LABEL)

# Run three binary classifiers
predict_target_1 = perceptron_setosa_versicolor.classify(TEST)
predict_target_2 = perceptron_setosa_virginica.classify(TEST)
predict_target_3 = perceptron_versicolor_virginica.classify(TEST)

overall_predict_result = []
for item in zip(predict_target_1, predict_target_2, predict_target_3):
    unique, counts = np.unique(item, return_counts=True)
    temp_result = (zip(unique, counts))
    # Sort by values and return the class that has majority votes
    overall_predict_result.append(sorted
            (temp_result, reverse=True, key=lambda tup: tup[1])[0][0])
    # The result should look like:
    # [('Iris-setosa', 2), ('Iris-versicolor', 1)]
    # [('Iris-setosa', 2), ('Iris-versicolor', 1)]
    # [('Iris-setosa', 2), ('Iris-versicolor', 1)]
    # [('Iris-setosa', 2), ('Iris-versicolor', 1)]
    # [('Iris-setosa', 2), ('Iris-versicolor', 1)]
    # [('Iris-setosa', 2), ('Iris-versicolor', 1)]
    # [('Iris-setosa', 2), ('Iris-versicolor', 1)]
    # [('Iris-setosa', 2), ('Iris-versicolor', 1)]
    # [('Iris-setosa', 2), ('Iris-versicolor', 1)]
    # [('Iris-setosa', 2), ('Iris-versicolor', 1)]
    # [('Iris-versicolor', 2), ('Iris-virginica', 1)]
    # [('Iris-versicolor', 2), ('Iris-virginica', 1)]
    # [('Iris-versicolor', 2), ('Iris-virginica', 1)]
    # [('Iris-versicolor', 2), ('Iris-virginica', 1)]
    # [('Iris-versicolor', 2), ('Iris-virginica', 1)]
    # [('Iris-versicolor', 2), ('Iris-virginica', 1)]
    # [('Iris-versicolor', 2), ('Iris-virginica', 1)]
    # [('Iris-versicolor', 2), ('Iris-virginica', 1)]
    # [('Iris-versicolor', 2), ('Iris-virginica', 1)]
    # [('Iris-versicolor', 2), ('Iris-virginica', 1)]
    # [('Iris-virginica', 2), ('Iris-versicolor', 1)]
    # [('Iris-virginica', 2), ('Iris-versicolor', 1)]
    # [('Iris-virginica', 2), ('Iris-versicolor', 1)]
    # [('Iris-virginica', 2), ('Iris-versicolor', 1)]
    # [('Iris-virginica', 2), ('Iris-versicolor', 1)]
    # [('Iris-virginica', 2), ('Iris-versicolor', 1)]
    # [('Iris-virginica', 2), ('Iris-versicolor', 1)]
    # [('Iris-virginica', 2), ('Iris-versicolor', 1)]
    # [('Iris-virginica', 2), ('Iris-versicolor', 1)]
    # [('Iris-virginica', 2), ('Iris-versicolor', 1)]

# Verify the results
misclassifier = 0
for predict, verify in zip(overall_predict_result, VERIFY):
    if predict != verify:
        misclassifier += 1
print("The number of misclassifier: " + str(misclassifier))
```

전체 코드는 https://github.com/burpeesDaily/ml-toybox/blob/main/mltoolbox/perceptron_classifier.py 에서 찾을 수 있습니다 .

## 학습이 가능한가?

많은 사람들이 기계 학습이 마법이라고 생각할 수 있습니다. 그렇지 않습니다. 사실 기계 학습은 수학, 특히 확률과 통계에 관한 것입니다.

### 학습 대 암기

학습이 실현 가능한지 보여주기 위해 학습이 무엇인지 정의해야 합니다. A Simple Example 섹션에서 Perceptron Learning Algorithm은 결국 모든 붓꽃을 분류하는 데 성공하지만 정말 학습하고 있는 것일까요? 아니면 그냥 암기하는 것입니까? 이러한 질문에 답하기 위해 샘플 내 오류와 샘플 외 오류를 정의합니다. 표본 내 오류는 표본 내 오류율을 의미합니다. 예를 들어 결국 Perceptron 학습 모델은 Iris Data Set의 모든 붓꽃을 분류할 수 있습니다. 샘플 내 오류는 0입니다. 즉, 오류가 전혀 없습니다. 표본외 오차는 표본내 오차와 달리 표본외 오차율을 의미한다. 즉, 학습 모델이 새로운 데이터를 보았을 때의 오류 수를 나타냅니다. 동일한 예를 들어 Perceptron 학습 모델에 새 데이터를 입력하면 오분류 비율은 표본외 오류입니다. 따라서 학습 모델이 실제 학습이라고 하려면 표본 내 오차가 작아야 할 뿐만 아니라 표본 외 오차도 작아야 합니다.

### 그렇다면 학습이 가능한가?

간단한 대답은 '예'입니다. 수학적 의미에서 학습이 가능합니다.

확률과 통계에서 학습이 가능하다는 것을 간략하게 보여줄 수 있는 두 가지 중요한 이론이 있습니다: 중심 극한 정리(Central Limit Theorem)와 대수의 법칙(Law of Large Number)입니다. 중심 극한 정리는 많은 수의 독립적이고 동일하게 분포된 변수의 평균 분포가 기본 분포에 관계없이 거의 정규 분포가 될 것이라고 말합니다. 다수의 법칙은 더 많은 샘플이 수집될수록 결과의 평균이 예상 값에 가까워야 하며 더 많은 시도를 수행할수록 더 가까워지는 경향이 있다고 설명합니다. 수학적 이론은 표본 비율 또는 표본 비율의 차이가 1인 한 정규 분포와 유사한 것을 따를 것임을 보장합니다. 표본의 관찰은 독립적입니다. 2. 샘플이 충분히 큽니다. 지나치게 단순화된 의미에서, 샘플 내에서 본 학습 결과는 샘플 외 데이터에서도 확인되어야 합니다. 따라서 학습이 가능합니다.

물론 이 진술은 지나치게 단순화된 것입니다. 기계 학습의 타당성을 뒷받침하는 이론의 세부 사항은 이 기사의 주제에서 벗어납니다. 이 주제를 다루는 많은 리소스가 있습니다. 내가 추천한 리소스 중 하나는 이 책, [Learning from Data](https://www.amazon.com/Learning-Data-Yaser-S-Abu-Mostafa-ebook/dp/B0759M2D9H/ref=sr_1_1?ie=UTF8&qid=1508470575&sr=8-1&keywords=learning+from+data) , 특히 ch2 VC Dimension to generalization입니다.

요컨대, 학습을 실현 가능하게 만들기 위해 학습 모델은 다음을 달성해야 합니다.

- 샘플 내 오차가 작음
- 샘플 외 오류는 샘플 내 오류에 가깝습니다.

## 우리가 잘 배우는지 어떻게 알 수 있습니까?

이전 섹션의 결론은 샘플 내 오류가 작고 샘플 외 오류가 샘플 내 오류에 가깝다면 학습 모델이 무언가를 학습한다는 것입니다. 표본내 오차가 작고 표본외 오차가 표본내 오차에 가깝다는 것은 무엇을 의미합니까? 표본내 오차는 얼마나 작아야 하고 표본외 오차는 얼마나 가까울 수 있습니까? 물론 샘플 내 오류와 샘플 외 오류가 모두 0이면 학습 모델이 완벽하게 학습됩니다. 불행하게도 실제 문제의 대부분은 그렇지 않습니다. 실제로 기계 학습 접근 방식은 이상적인 대상 기능을 찾는 것이 아닙니다. ![에프](https://www.codeproject.com/KB/Articles/1211753/329b0474-b907-4f43-af0c-857c79dc33cd.Png)대신 기계 학습 접근 방식은 목표 함수에 근접하는 가설 함수를 찾습니다.![g](https://www.codeproject.com/KB/Articles/1211753/4d3c6d0d-7b2a-4df5-bae2-1dd6ea15fa49.Png). (대상 함수는 항상 알 수 없습니다. 그렇지 않으면 기계 학습 접근 방식을 사용하지 않을 것입니다.) 즉, 기계 학습 접근 방식은 에 충분히 가까운 충분한 솔루션을 ![에프](https://www.codeproject.com/KB/Articles/1211753/3f2d91f0-2043-4909-b5a5-ae5dfdf1b576.Png)찾습니다 ![g](https://www.codeproject.com/KB/Articles/1211753/7284043d-984d-472e-848d-911397761b84.Png). 충분해은 무슨 뜻인가요? ![에프](https://www.codeproject.com/KB/Articles/1211753/7c80b76a-2d02-462e-b991-8c6e64db57fb.Png)에 얼마나 가까운지를 정량화하려면 과 ![g](https://www.codeproject.com/KB/Articles/1211753/1c962ab1-42a5-40b5-92fb-4790f86ec13d.Png)사이의 거리를 정의하는 방법이 필요합니다 . 일반적으로 오류 측정 또는 오류 함수라고 합니다(오류는 비용 또는 위험이라고도 함).![에프](https://www.codeproject.com/KB/Articles/1211753/11ac999e-0a6f-44fc-982c-6cba8c4d778c.Png)![g](https://www.codeproject.com/KB/Articles/1211753/fa14218c-04e2-42ca-85e9-cb60cd68869c.Png)

### 오차 측정

일반적으로 예상 및 예측 출력이라는 두 가지 인수를 취하고 전체 데이터 세트에 대한 총 오류 값을 계산하여 음수가 아닌 오류 측정을 정의합니다.

![오차 = E \left( h, g \right)](https://www.codeproject.com/KB/Articles/1211753/98c27157-838a-490f-b1ad-3aeaef6c1fd3.Png), 여기서 ![시간](https://www.codeproject.com/KB/Articles/1211753/151b2904-431f-45dd-b5e0-65d7916775a7.Png)는 가설이고 ![g](https://www.codeproject.com/KB/Articles/1211753/659bf279-b202-47b1-bde9-524fe1fc400d.Png)대상 함수입니다. ![E \왼쪽( h, g \오른쪽)](https://www.codeproject.com/KB/Articles/1211753/8f3f4a05-522f-4e5e-86b3-75027f4d8304.Png)개별 입력의 오류를 기반으로 합니다 ![x_i](https://www.codeproject.com/KB/Articles/1211753/036f734a-3638-40c8-b472-5bac48f6cf18.Png). 따라서 pointwise error measure 를 정의할 수 있습니다 ![e \left( h \left( x_i \right), g \left( x_i \right) \right)](https://www.codeproject.com/KB/Articles/1211753/1d6aa13a-5345-4ea6-9922-bdb984fc97d5.Png). 그러면 전체 오차는 이 점별 오차의 평균값입니다.![오류_{전체} = \frac{1}{n} \sum_{i=1}^{n} |  h \left( x_i \right) - g \left( x_i \right) |](https://www.codeproject.com/KB/Articles/1211753/c47efb96-2d5e-439b-8e91-ac4ecc8ea129.Png)

오류 측정의 선택은 학습 모델의 선택에 영향을 미칩니다. 데이터셋과 목적함수가 같더라도 문제에 따라 오차측정의 의미가 달라질 수 있다. 예를 들어 이메일 스팸 분류기가 있습니다. 이 이메일 스팸 문제에 대한 학습 모델의 두 가지 오류 결과가 있습니다. 거짓 긍정 및 거짓 부정입니다. 전자는 이메일이 스팸임을 의미하지만 학습 모델은 스팸이 아니라고 판단합니다. 후자는 학습 모델이 이메일이 스팸이라고 말하지만 스팸이 아님을 나타냅니다. 개인 이메일 계정과 작업 이메일 계정의 두 가지 시나리오를 상상해 보십시오.

개인 이메일 계정의 경우 학습 모델이 스팸 이메일을 걸러내지 못한다면 아마 괜찮을 것입니다. 짜증나. 반면에 학습 모델이 스팸이 아닌 일부 이메일(예: 친구 또는 신용 카드 회사의 이메일)을 필터링하는 경우. 이 경우에도 괜찮을 것입니다. 아래 표를 사용하여 이 사례를 측정할 수 있습니다.

|                                 | **이메일은 스팸입니다** | **이메일은 스팸이 아닙니다** |
| ------------------------------- | ----------------------- | ---------------------------- |
| **이메일을 스팸으로 분류**      | 0                       | 1                            |
| **이메일이 스팸이 아닌지 분류** | 1                       | 0                            |

학습 모델이 이메일을 올바르게 분류하면 이 오류의 비용은 0입니다. 그렇지 않으면 비용은 1입니다.

다른 경우: 작업 중인 이메일 계정. 개인 계정과 마찬가지로 학습 모델이 스팸을 걸러내지 못하면 짜증나지만 괜찮습니다. 그러나 학습 모델이 상사의 이메일을 스팸으로 분류하고 이러한 이메일을 놓치게 한다면 괜찮지 않을 수 있습니다. 따라서 이 경우 위음성의 비용은 앞의 예보다 가중치가 더 큽니다.

|                                 | **이메일은 스팸입니다** | **이메일은 스팸이 아닙니다** |
| ------------------------------- | ----------------------- | ---------------------------- |
| **이메일을 스팸으로 분류**      | 0                       | 10                           |
| **이메일이 스팸이 아닌지 분류** | 1                       | 0                            |

다시 말하지만 오류 함수(또는 비용 함수, 위험 함수)는 실제로 다양한 문제에 따라 다르며 고객이 정의해야 합니다.

### 과적합과 과소적합

Is Learning Feasible 섹션의 결론은 학습이 가능하려면 학습 모델이 샘플 내 오류가 작고 샘플 외 오류가 샘플 내 오류에 가까워야 함을 보여줍니다. 일반적으로 훈련 세트는 전역 분포를 나타내지만 가능한 모든 요소를 포함할 수는 없습니다. 따라서 모델을 훈련할 때 훈련 데이터를 맞추려고 노력해야 합니다. , 샘플 외 오차를 작게 유지하십시오. 안타깝게도 이 이상적인 조건은 찾기가 쉽지 않으며, 과적합과 과소적합이라는 두 가지 현상에 주의하는 것이 중요합니다.

그림은 두 클래스 데이터에 대한 정상적인 분류를 보여줍니다.

![이미지 75](https://www.codeproject.com/KB/Articles/1211753/normal_fitting.PNG)

Underfitting은 학습 모델이 교육 데이터 세트에 표시된 패턴을 캡처할 수 없음을 의미합니다. 아래 그림은 과소적합의 경우를 보여줍니다.

![이미지 76](https://www.codeproject.com/KB/Articles/1211753/under_fitting.PNG)

일반적으로 과소적합은 발생 시 학습 모델이 샘플 내 데이터에 잘 맞지 않기 때문에 관찰하기 쉽습니다. 즉, 과소적합이 발생하면 표본 내 오류가 높습니다.

과대적합은 과소적합의 반대입니다. 이는 학습 모델이 훈련 데이터에 매우 잘 맞지만 샘플 외 데이터에는 너무 잘 맞는다는 것을 의미합니다. 즉, 과적합 학습 모델은 일반화를 잃기 때문에 알 수 없는 입력이 제시될 때 해당 예측 오류가 매우 높을 수 있습니다.

![이미지 77](https://www.codeproject.com/KB/Articles/1211753/overfitting.PNG)

과소적합과 달리 과적합은 학습 모델의 샘플 내 오류가 일반적으로 매우 낮기 때문에 알아차리거나 방지하기 어렵습니다. 우리는 새로운 데이터가 올 때까지 이 모델을 매우 잘 훈련했다고 생각할 수 있으며, 표본 외 오류가 높습니다. 그런 다음 모델이 과적합되었음을 알게 됩니다.

과적합은 일반적으로 학습 모델이 대상 기능을 나타내는 데 필요한 것보다 더 복잡한 경우에 발생합니다. 과적합 문제는 간단히 말해서 다음과 같이 요약할 수 있습니다.

- 데이터 포인트 수가 증가하고 과적합 가능성이 감소합니다.
- 데이터 세트에 노이즈가 많으면 과적합될 가능성이 높습니다.
- 모델이 복잡할수록 과적합이 더 쉽게 발생합니다.

## 학습 유형

데이터 유형과 해결하려는 문제에 따라 학습 문제를 지도 학습, 비지도 학습 및 강화 학습의 세 그룹으로 대략 분류할 수 있습니다.

### 감독 학습

감독 학습은 아마도 가장 잘 연구된 학습 문제일 것입니다. 기본적으로 감독 학습에서 각 샘플에는 입력 데이터와 명시적 출력, 즉 올바른 출력이 포함됩니다. 즉, 감독 학습은 (입력, 올바른 출력)으로 형성될 수 있습니다.

홍채 데이터 세트는 전형적인 감독 학습입니다. 데이터 세트에는 꽃받침 길이, 꽃받침 너비, 꽃잎 길이, 꽃잎 너비 및 올바른 출력, 붓꽃 식물 유형의 5가지 속성이 입력으로 있습니다. Iris 데이터 세트를 플로팅하여 지도 학습을 시각화할 수 있습니다. 단순화를 위해 꽃받침 길이와 꽃잎 길이를 입력으로 취하고 각 클래스를 표시하기 위해 서로 다른 색상과 기호를 사용하여 2D 그림을 플로팅합니다.

![이미지 78](https://www.codeproject.com/KB/Articles/1211753/supervised_learning-r-700.png)

샘플 코드는 https://github.com/burpeesDaily/formosa1544/blob/main/machine-learning-basics-and-perceptron-learning-algorithm/supervised.py 에서 찾을 수 있습니다 .

감독 학습의 주요 목표는 보이지 않는 데이터 또는 미래 데이터에 대한 예측을 수행하기 위해 올바른 레이블이 있는 데이터에서 모델을 학습하는 것입니다. 일반적인 감독 학습 문제는 다음과 같습니다. 스팸 감지, 패턴 감지 인스턴스, 자연어 처리와 같은 지속적인 결과를 예측하기 위한 클래스 레이블 및 회귀 예측을 위한 분류.

### 비지도 학습

지도 학습과 달리 비지도 학습의 데이터 세트는 올바른 출력을 포함하지 않으며 (입력, ?)

유형을 다른 색상으로 표시하지 않으면 Iris 데이터 세트는 비지도 학습의 예가 됩니다.

![이미지 79](https://www.codeproject.com/KB/Articles/1211753/a5548d3f-f3e9-4592-87c5-9090ffdb5413.Png)

샘플 코드는 https://github.com/burpeesDaily/formosa1544/blob/main/machine-learning-basics-and-perceptron-learning-algorithm/unsupervised.py 에서 찾을 수 있습니다 .

대부분의 경우 데이터 세트에는 위의 그림과 같이 입력만 있고 올바른 출력이 포함되어 있지 않습니다. 그렇다면 비지도 학습 문제에서 어떻게 무언가를 배울 수 있을까요? 다행스럽게도 올바른 출력은 없지만 입력에서 무언가를 배울 수 있습니다. 예를 들어 위의 그림에서 각 타원은 클러스터를 나타내며 해당 영역 내의 모든 점은 동일한 방식으로 레이블을 지정할 수 있습니다. (물론 우리는 Iris 데이터 세트에 3개의 클래스가 있다는 것을 알았습니다. 여기서는 Iris 데이터 세트에 3개의 클래스가 있다는 것을 모른 척합니다). 비지도 학습 기법을 사용하여 그룹에 대한 사전 지식 없이 의미 있는 정보를 추출하기 위해 데이터 세트의 구조를 탐색할 수 있습니다. 비지도 학습 문제는 레이블이 붙지 않기 때문에 비지도 학습으로 숨겨진 구조를 발견하는 것과 같은 문제를 다루고,

### 강화 학습

출력이 있는 지도 학습과 올바른 출력이 없는 비지도 학습과 달리 강화 학습의 데이터 세트는 입력과 일부 출력 등급을 포함하며 (입력, 등급이 있는 일부 출력)으로 구성될 수 있습니다.

강화 학습의 한 가지 좋은 예는 체스와 바둑과 같은 게임을 하는 것입니다. 다음 단계의 결정은 현재 상태의 피드백을 기반으로 합니다. 새 단계가 결정되면 이 단계의 등급이 관찰됩니다. 강화 학습의 목표는 가장 유용한 작업의 순서를 찾는 것이므로 강화 학습 모델은 항상 최선의 결정을 내릴 수 있습니다.

### 온라인 대 오프라인

학습 문제는 모델을 훈련시키는 방법으로도 볼 수 있습니다.

#### 온라인 학습

데이터 세트는 한 번에 하나씩 알고리즘에 제공됩니다. 온라인 학습은 알고리즘이 ''실행 중'' 처리해야 하는 스트리밍 데이터가 있을 때 발생합니다.

#### 오프라인 학습

대신 알고리즘에 한 번에 하나의 예를 제공합니다. 처음에는 알고리즘을 훈련할 많은 데이터가 있습니다. 홍채 데이터 세트 예제는 오프라인 학습입니다.

온라인 및 오프라인 학습 모두 지도, 비지도 및 강화에 적용할 수 있습니다.

## 기계 학습의 과제

기계 학습(ML) 및 인공 지능(AI)의 발전으로 많은 AI/ML 기반 도구 및 프로그램이 많은 분야에서 무한한 가능성을 보여주었습니다. 그러나 기계 학습은 많은 사람들이 생각하는 것만큼 강력하지 않습니다. 대신 많은 연구자들이 해결하고자 하는 중요한 약점이 많이 있습니다. 다음은 오늘날 기계 학습 산업이 직면한 몇 가지 과제입니다.

우선, 학습된 모델을 하나의 학습 문제에서 다른 학습 문제로 전환하는 쉬운 방법이 없습니다. 인간으로서 우리가 바둑을 두는 것과 같은 한 가지에 능숙할 때 추격, 브리지 또는 적어도 배우기 쉬운 것과 같은 유사한 게임도 잘할 가능성이 있습니다. 안타깝게도 기계 학습의 경우 문제가 다른 문제와 유사하더라도 모든 단일 문제에 대해 학습 프로세스를 다시 시작해야 합니다. 예를 들어, 이전 섹션에서 붓꽃을 분류하기 위해 훈련한 퍼셉트론 학습 모델은 더 이상 붓꽃을 분류하는 것이 아닙니다. 서로 다른 꽃을 분류하려면 처음부터 새로운 학습 모델을 훈련해야 합니다.

두 번째 문제는 데이터에 레이블을 지정하는 현명한 방법이 없다는 것입니다. 기계 학습은 많은 일을 할 수 있으며 모든 종류의 데이터에서 배울 수 있습니다. 그럼에도 불구하고 데이터에 레이블을 지정하는 방법을 모릅니다. 예, 우리는 많은 고양이 사진을 먹임으로써 동물, 예를 들어 고양이를 인식하도록 학습 모델을 훈련시킬 수 있습니다. 그러나 처음에는 사람인 누군가가 사진에 고양이 사진인지 아닌지 라벨을 붙여야 합니다. 비지도 학습이 데이터를 그룹화하는 데 도움이 될 수 있지만 사진 그룹이 고양이인지 아닌지는 여전히 알 수 없습니다. 오늘날 데이터 라벨링에는 여전히 사람의 개입이 필요합니다.

셋째, 머신러닝 솔루션을 만든 사람도 왜 머신러닝 솔루션이 이런 결정을 내리는지 모른다. 기계 학습의 본질은 데이터로부터 학습하는 것입니다. 우리는 학습 모델에 데이터를 공급하고 결과를 예측합니다. Perceptron Learning Algorithm 예제에서 최종 가설의 가중치는 [-4.0, -8.6, 14.2]처럼 보일 수 있지만 학습 모델이 이러한 가중치를 부여한 이유를 설명하기는 쉽지 않습니다. 가장 단순한 학습 알고리즘인 퍼셉트론도 그 이유를 설명할 수 없습니다. 말할 필요도 없이, 더 정교한 학습 알고리즘이 어떻게 작동하는지 설명하는 것은 거의 불가능합니다. 이 문제는 심각한 결과를 초래할 수 있습니다. 특히 자율주행차와 같이 오류 비용이 높은 학습 문제의 경우 문제가 발생하고 어떻게 잘못되는지 알지 못한다면 어떻게 고칠 수 있습니까?

이 세 가지 과제는 빙산의 일각에 불과합니다. 기계 학습은 무한한 잠재력을 가지고 있는 것처럼 보이지만 아직 갈 길이 멉니다.

[이 기사는 원래 https://shunsvinyard.blog/2017/10/22/machine-learning-basics-and-perceptron-learning-algorithm](https://shunsvinyard.blog/2017/10/22/machine-learning-basics-and-perceptron-learning-algorithm) 에 게시되었습니다.

## 특허

이 문서는 관련 소스 코드 및 파일과 함께 [The Code Project Open License(CPOL) 에 따라 사용이 허가되었습니다.](http://www.codeproject.com/info/cpol10.aspx)

![img](https://www.gravatar.com/avatar/c620c3f6b48335b97fd9657f578aebb5.jpg?d=identicon&s=150&r=pg)

작성자

**[황 순](https://www.codeproject.com/Members/burpeesDaily)**

소프트웨어 개발자(시니어)

![미국](https://www.codeproject.com/script/Geo/Images/US.gif) 미국

제 이름은 슌입니다. 저는 소프트웨어 엔지니어이자 기독교인입니다. 현재 스타트업 회사에서 일하고 있습니다.
내 웹사이트: https://formosa1544.com
이메일: shun@formosa1544.com